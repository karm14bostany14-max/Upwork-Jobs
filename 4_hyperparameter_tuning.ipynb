{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05bb464e-0cdc-4716-8c96-874c68e09945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 4) Hiperparametre Ayarlama (Hyperparameter Tuning)\n",
    "# Upwork Jobs (Tek CSV, Hafif Versiyon)\n",
    "# Çalışan sütunlar: ['title','link','published_date','is_hourly','hourly_low','hourly_high','budget','country']\n",
    "# ============================================================\n",
    "\n",
    "import os, numpy as np, pandas as pd, tempfile\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, classification_report,\n",
    "    r2_score, mean_absolute_error, root_mean_squared_error\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9139a7c-edee-4255-8ab6-a2c17de09747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: (244828, 8) ['title', 'link', 'published_date', 'is_hourly', 'hourly_low', 'hourly_high', 'budget', 'country']\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Tek CSV dosyasını yükleme (birleştirme yok)\n",
    "# ---------------------------\n",
    "DATA_DIR = r\"C:\\Users\\karm1\\OneDrive\\Desktop\\Upwork_Project\\data\"\n",
    "CSV_FILE = \"all_upwork_jobs_2024-02-07-2024-03-24.csv\"   # Farklı dosya kullanıyorsan burayı güncelle\n",
    "csv_path = os.path.join(DATA_DIR, CSV_FILE)\n",
    "if not os.path.isfile(csv_path):\n",
    "    raise FileNotFoundError(f\"CSV not found at: {csv_path}\")\n",
    "\n",
    "# CSV dosyasını oku\n",
    "df = pd.read_csv(csv_path, low_memory=False)\n",
    "print(\"Loaded:\", df.shape, list(df.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f257538-0f10-485a-932e-cb7d9a3d6056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 1) Özellik Mühendisliği (Feature Engineering)\n",
    "# ---------------------------\n",
    "\n",
    "# hourly_low + hourly_high ortalamasından hourly_rate sütunu oluştur\n",
    "if {\"hourly_low\",\"hourly_high\"}.issubset(df.columns):\n",
    "    df[\"hourly_rate\"] = (pd.to_numeric(df[\"hourly_low\"], errors=\"coerce\")\n",
    "                         + pd.to_numeric(df[\"hourly_high\"], errors=\"coerce\"))/2\n",
    "\n",
    "# is_hourly sütununu 0 / 1 formatına dönüştür (sabit mi, saatlik mi)\n",
    "def map_hourly(v):\n",
    "    s = str(v).strip().lower()\n",
    "    if s in [\"1\",\"true\",\"yes\",\"y\",\"hourly\",\"hourly_job\",\"t\"]: return 1\n",
    "    if s in [\"0\",\"false\",\"no\",\"n\",\"fixed\",\"fixed_price\",\"f\"]: return 0\n",
    "    try: return int(v)\n",
    "    except: return np.nan\n",
    "if \"is_hourly\" in df.columns:\n",
    "    df[\"is_hourly\"] = df[\"is_hourly\"].apply(map_hourly)\n",
    "\n",
    "# Sayısal sütunları dönüştür\n",
    "for c in [\"budget\",\"hourly_rate\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37681f6b-4d21-406d-b6c9-0a149213eed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eksik değerleri doldur, metin sütunlarını hazırla\n",
    "df[\"title\"] = df.get(\"title\",\"\").astype(str).fillna(\"\")\n",
    "df[\"country\"] = df.get(\"country\",\"unknown\").astype(str).fillna(\"unknown\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed79b58d-c3ab-47a2-916b-f5aced51e072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working sample: (40000, 9)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 2) Örnekleme (Sample for speed)\n",
    "# ---------------------------\n",
    "# Büyük veriyle GridSearch çok yavaş olabileceği için örnekleme yapılıyor\n",
    "SAMPLE_MAX = 40000   # Hızlı test için 40K satır, gerekirse artırılabilir\n",
    "df_s = df.sample(SAMPLE_MAX, random_state=42) if len(df) > SAMPLE_MAX else df.copy()\n",
    "print(\"Working sample:\", df_s.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcbae0ca-a3f4-4a38-9768-35d8b3e172f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline cache: C:\\Users\\karm1\\AppData\\Local\\Temp\\tmpgos1oap9\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 3) Ön İşleme (Preprocessing)\n",
    "# ---------------------------\n",
    "# TF-IDF (title) + OneHot (country)\n",
    "pre_sparse = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"txt\", TfidfVectorizer(max_features=4000, ngram_range=(1,2)), \"title\"),  # Metin özellikleri\n",
    "        (\"cty\", OneHotEncoder(handle_unknown=\"ignore\"), [\"country\"]),             # Ülke özellikleri\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    verbose_feature_names_out=False\n",
    ")\n",
    "\n",
    "# Pipeline cache (geçici dizin) — tekrar eden modelleri hızlandırır\n",
    "CACHE_DIR = tempfile.mkdtemp()\n",
    "print(\"Pipeline cache:\", CACHE_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ba163f2-e509-42be-811c-71c45f4a3b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[A] CLS Train: (32000, 2) Test: (8000, 2)\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Best LOG params: {'clf__C': 0.5}  best F1: 0.7229122200546976\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------\n",
    "# A) Sınıflandırma (Classification): is_hourly tahmini\n",
    "# ---------------------------------\n",
    "if \"is_hourly\" in df_s.columns and df_s[\"is_hourly\"].dropna().nunique()==2:\n",
    "    dcls = df_s.dropna(subset=[\"is_hourly\"]).copy()\n",
    "    Xc = dcls[[\"title\",\"country\"]]   # Girdi özellikleri\n",
    "    yc = dcls[\"is_hourly\"].astype(int)  # Hedef: 0 veya 1\n",
    "\n",
    "    # Veriyi eğitim (%80) ve test (%20) olarak ayır\n",
    "    Xc_train, Xc_test, yc_train, yc_test = train_test_split(\n",
    "        Xc, yc, test_size=0.2, random_state=42, stratify=yc\n",
    "    )\n",
    "    print(\"\\n[A] CLS Train:\", Xc_train.shape, \"Test:\", Xc_test.shape)\n",
    "\n",
    "    # --- Logistic Regression modeli için hiperparametre ayarı ---\n",
    "    pipe_log = Pipeline(steps=[\n",
    "        (\"pre\", pre_sparse),\n",
    "        (\"clf\", LogisticRegression(max_iter=800, solver=\"liblinear\"))\n",
    "    ], memory=CACHE_DIR)\n",
    "\n",
    "    # C (regularization strength) için grid araması\n",
    "    grid_log = GridSearchCV(\n",
    "        pipe_log,\n",
    "        param_grid={\"clf__C\":[0.5, 1.0, 2.0]},   # Küçük grid (hızlı)\n",
    "        scoring=\"f1\",\n",
    "        cv=3, n_jobs=-1, verbose=1\n",
    "    )\n",
    "    grid_log.fit(Xc_train, yc_train)\n",
    "    print(\"Best LOG params:\", grid_log.best_params_, \" best F1:\", grid_log.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23daf8be-ee77-4cfc-806f-6c88d1597b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Best RF params: {'clf__max_depth': 25, 'clf__n_estimators': 300}  best F1: 0.714214984057763\n"
     ]
    }
   ],
   "source": [
    "    # --- Random Forest modeli için hiperparametre ayarı ---\n",
    "    # RandomForest, sparse veriyle çalışamadığı için TruncatedSVD ile boyut indirgeme yapılır\n",
    "    pipe_rf = Pipeline(steps=[\n",
    "        (\"pre\", pre_sparse),\n",
    "        (\"svd\", TruncatedSVD(n_components=150, random_state=42)),   # Boyut indirgeme (daha hafif)\n",
    "        (\"clf\", RandomForestClassifier(random_state=42, n_jobs=-1))\n",
    "    ], memory=CACHE_DIR)\n",
    "\n",
    "    param_rf = {\n",
    "        \"clf__n_estimators\":[200, 300],  # Ağaç sayısı\n",
    "        \"clf__max_depth\":[None, 25]      # Maksimum derinlik\n",
    "    }\n",
    "    grid_rf = GridSearchCV(\n",
    "        pipe_rf, param_grid=param_rf, scoring=\"f1\", cv=3, n_jobs=-1, verbose=1\n",
    "    )\n",
    "    grid_rf.fit(Xc_train, yc_train)\n",
    "    print(\"Best RF params:\", grid_rf.best_params_, \" best F1:\", grid_rf.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f68e896-ea6d-4885-b8b6-499d274be67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[name=LogReg] ACC=0.6488 F1=0.7217\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.614     0.457     0.524      3384\n",
      "           1      0.665     0.789     0.722      4616\n",
      "\n",
      "    accuracy                          0.649      8000\n",
      "   macro avg      0.639     0.623     0.623      8000\n",
      "weighted avg      0.643     0.649     0.638      8000\n",
      "\n",
      "\n",
      "[name=RF] ACC=0.6440 F1=0.7208\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.611     0.436     0.509      3384\n",
      "           1      0.658     0.797     0.721      4616\n",
      "\n",
      "    accuracy                          0.644      8000\n",
      "   macro avg      0.635     0.616     0.615      8000\n",
      "weighted avg      0.638     0.644     0.631      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if \"is_hourly\" in df_s.columns and df_s[\"is_hourly\"].dropna().nunique()==2:\n",
    "\n",
    "    # --- En iyi modelleri test kümesinde değerlendir ---\n",
    "    for name, model in [(\"LogReg\", grid_log.best_estimator_), (\"RF\", grid_rf.best_estimator_)]:\n",
    "        pred = model.predict(Xc_test)\n",
    "        acc = accuracy_score(yc_test, pred)\n",
    "        f1  = f1_score(yc_test, pred)\n",
    "        print(f\"\\n[name={name}] ACC={acc:.4f} F1={f1:.4f}\")\n",
    "        print(classification_report(yc_test, pred, digits=3))\n",
    "\n",
    "else:\n",
    "    print(\"\\n[A] Classification skipped: 'is_hourly' not binary/available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cefb6e-495b-4c08-99e5-646cf82b1c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[B] REG Fixed Rows=16920 Train:(13536, 2) Test:(3384, 2)\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------\n",
    "# B) Regresyon (Fixed Jobs): 'budget' tahmini\n",
    "# ------------------------------------------------\n",
    "reg_fixed_done = False\n",
    "if {\"is_hourly\",\"budget\"}.issubset(df_s.columns):\n",
    "    dregF = df_s[(df_s[\"is_hourly\"]==0) & (df_s[\"budget\"].notna())].copy()\n",
    "    if len(dregF) >= 200:\n",
    "        XrF = dregF[[\"title\",\"country\"]]\n",
    "        yrF = dregF[\"budget\"].astype(float)\n",
    "\n",
    "        XrF_train, XrF_test, yrF_train, yrF_test = train_test_split(\n",
    "            XrF, yrF, test_size=0.2, random_state=42\n",
    "        )\n",
    "        print(f\"\\n[B] REG Fixed Rows={len(dregF)} Train:{XrF_train.shape} Test:{XrF_test.shape}\")\n",
    "\n",
    "        # Pipeline: TF-IDF + OneHot + SVD + RandomForestRegressor\n",
    "        pipe_rfr = Pipeline(steps=[\n",
    "            (\"pre\", pre_sparse),\n",
    "            (\"svd\", TruncatedSVD(n_components=150, random_state=42)),\n",
    "            (\"reg\", RandomForestRegressor(random_state=42, n_jobs=-1))\n",
    "        ], memory=CACHE_DIR)\n",
    "\n",
    "        # Hiperparametre aralığı (n_estimators ve max_depth)\n",
    "        grid_rfr = GridSearchCV(\n",
    "            pipe_rfr,\n",
    "            param_grid={\"reg__n_estimators\":[200, 300], \"reg__max_depth\":[None, 25]},\n",
    "            scoring=\"neg_root_mean_squared_error\",  # Hedef: RMSE’yi minimize etmek\n",
    "            cv=3, n_jobs=-1, verbose=1\n",
    "        )\n",
    "        grid_rfr.fit(XrF_train, yrF_train)\n",
    "\n",
    "        # En iyi modelin performansını test setinde ölç\n",
    "        best_regF = grid_rfr.best_estimator_\n",
    "        predF = best_regF.predict(XrF_test)\n",
    "        r2F = r2_score(yrF_test, predF)\n",
    "        maeF = mean_absolute_error(yrF_test, predF)\n",
    "        rmseF = root_mean_squared_error(yrF_test, predF)\n",
    "        print(\"Best RFReg (Fixed) params:\", grid_rfr.best_params_,\n",
    "              \" | Test -> R2={:.4f} MAE={:.2f} RMSE={:.2f}\".format(r2F, maeF, rmseF))\n",
    "        reg_fixed_done = True\n",
    "\n",
    "if not reg_fixed_done:\n",
    "    print(\"\\n[B] Regression (Fixed) skipped: need many rows with is_hourly==0 and budget numeric.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef3d5e9-0eb0-498f-9d7e-3ee85e94c04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# C) Regresyon (Hourly Jobs): 'hourly_rate' tahmini\n",
    "# ---------------------------------------------------\n",
    "reg_hourly_done = False\n",
    "if {\"is_hourly\",\"hourly_rate\"}.issubset(df_s.columns):\n",
    "    dregH = df_s[(df_s[\"is_hourly\"]==1) & (df_s[\"hourly_rate\"].notna())].copy()\n",
    "    if len(dregH) >= 200:\n",
    "        XrH = dregH[[\"title\",\"country\"]]\n",
    "        yrH = dregH[\"hourly_rate\"].astype(float)\n",
    "\n",
    "        XrH_train, XrH_test, yrH_train, yrH_test = train_test_split(\n",
    "            XrH, yrH, test_size=0.2, random_state=42\n",
    "        )\n",
    "        print(f\"\\n[C] REG Hourly Rows={len(dregH)} Train:{XrH_train.shape} Test:{XrH_test.shape}\")\n",
    "\n",
    "        pipe_rfrH = Pipeline(steps=[\n",
    "            (\"pre\", pre_sparse),\n",
    "            (\"svd\", TruncatedSVD(n_components=150, random_state=42)),\n",
    "            (\"reg\", RandomForestRegressor(random_state=42, n_jobs=-1))\n",
    "        ], memory=CACHE_DIR)\n",
    "\n",
    "        grid_rfrH = GridSearchCV(\n",
    "            pipe_rfrH,\n",
    "            param_grid={\"reg__n_estimators\":[200, 300], \"reg__max_depth\":[None, 25]},\n",
    "            scoring=\"neg_root_mean_squared_error\",\n",
    "            cv=3, n_jobs=-1, verbose=1\n",
    "        )\n",
    "        grid_rfrH.fit(XrH_train, yrH_train)\n",
    "\n",
    "        best_regH = grid_rfrH.best_estimator_\n",
    "        predH = best_regH.predict(XrH_test)\n",
    "        r2H = r2_score(yrH_test, predH)\n",
    "        maeH = mean_absolute_error(yrH_test, predH)\n",
    "        rmseH = root_mean_squared_error(yrH_test, predH)\n",
    "        print(\"Best RFReg (Hourly) params:\", grid_rfrH.best_params_,\n",
    "              \" | Test -> R2={:.4f} MAE={:.2f} RMSE={:.2f}\".format(r2H, maeH, rmseH))\n",
    "        reg_hourly_done = True\n",
    "\n",
    "if not reg_hourly_done:\n",
    "    print(\"\\n[C] Regression (Hourly) skipped: need rows with is_hourly==1 and hourly_rate numeric.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c212958-cf76-4c69-bf1e-6ce79c74f22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n Hiperparametre ayarlama başarıyla tamamlandı.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
